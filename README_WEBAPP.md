# VoiceMood AI - Modern Web Application

A professional emotion detection and music recommendation system built with **Next.js** and **FastAPI**.

## ğŸš€ Tech Stack

### Frontend
- **Next.js 14** - React framework
- **TypeScript** - Type safety
- **Tailwind CSS** - Styling
- **Framer Motion** - Animations
- **Axios** - HTTP client
- **Lucide React** - Icons

### Backend
- **FastAPI** - Python web framework
- **PyTorch** - Deep learning
- **librosa** - Audio processing
- **CUDA** - GPU acceleration

## ğŸ“¦ Installation

### Prerequisites
- **Node.js** 18+ and npm
- **Python** 3.8+
- **CUDA Toolkit** 12.1 (for GPU acceleration)

### Backend Setup

1. **Navigate to backend directory:**
```powershell
cd backend
```

2. **Create virtual environment (optional but recommended):**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

3. **Install PyTorch with CUDA:**
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

4. **Install other dependencies:**
```powershell
pip install fastapi uvicorn python-multipart librosa soundfile numpy pandas scikit-learn joblib
```

5. **Start the FastAPI server:**
```powershell
python main.py
```

Server will run at: `http://localhost:8000`

### Frontend Setup

1. **Navigate to frontend directory:**
```powershell
cd frontend
```

2. **Install dependencies:**
```powershell
npm install
```

3. **Start the development server:**
```powershell
npm run dev
```

Frontend will run at: `http://localhost:3000`

## ğŸ¯ Usage

1. **Start the backend** (`http://localhost:8000`)
2. **Start the frontend** (`http://localhost:3000`)
3. **Open browser** and go to `http://localhost:3000`
4. **Upload a .wav file** (drag & drop or click to browse)
5. **View results**: emotion detection + music recommendations

## ğŸ“ Project Structure

```
ai_project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ api/                 # API routes (if expanded)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx         # Main page
â”‚   â”‚   â”œâ”€â”€ layout.tsx       # Root layout
â”‚   â”‚   â””â”€â”€ globals.css      # Global styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Header.tsx       # Header component
â”‚   â”‚   â”œâ”€â”€ AudioUploader.tsx # File upload
â”‚   â”‚   â”œâ”€â”€ EmotionResult.tsx # Results display
â”‚   â”‚   â””â”€â”€ MusicRecommendations.tsx # Music cards
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts           # API client
â”‚   â”‚   â””â”€â”€ utils.ts         # Utilities
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env.local           # Environment variables
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ model_utils.py       # PyTorch model logic
â”‚   â””â”€â”€ music_utils.py       # Music recommendations
â”‚
â”œâ”€â”€ config.py                # Configuration
â”œâ”€â”€ best_emotion_model.pth   # Trained model
â”œâ”€â”€ scaler2.pickle           # Feature scaler
â”œâ”€â”€ encoder2.pickle          # Label encoder
â””â”€â”€ songs.csv                # Music database
```

## ğŸ”Œ API Endpoints

- `GET /` - API info
- `GET /health` - Health check
- `GET /api/emotions` - List of emotions
- `POST /api/detect` - Detect emotion from audio
- `GET /api/stats` - Model statistics

## ğŸ¨ Features

- âœ¨ **Modern UI** - Beautiful dark theme with animations
- ğŸµ **Drag & Drop** - Easy file upload
- ğŸ“Š **Confidence Scores** - Visual confidence bars
- ğŸ§ **Music Recommendations** - Personalized song suggestions
- âš¡ **Real-time Processing** - Fast emotion detection
- ğŸ“± **Responsive Design** - Works on all devices
- ğŸš€ **GPU Accelerated** - CUDA support for faster inference

## ğŸ§ª Model Details

- **Architecture:** CNN (7.1M parameters)
- **Accuracy:** 97.09%
- **Emotions:** Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
- **Datasets:** RAVDESS, CREMA-D, TESS, SAVEE
- **Input:** .wav audio files (2.5s, 22050Hz)
- **Features:** MFCC, ZCR, RMSE

## âš ï¸ Important Notes

- Model trained on **professional acted speech**
- Best results with **clear, exaggerated emotional expressions**
- Use **.wav format** for audio files
- GPU recommended for faster processing

## ğŸ“ Development Commands

### Backend
```powershell
# Run server with auto-reload
python main.py

# Or use uvicorn directly
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend
```powershell
# Development server
npm run dev

# Build for production
npm run build

# Start production server
npm start

# Lint code
npm run lint
```

## ğŸš€ Deployment

### Frontend (Vercel)
1. Push code to GitHub
2. Connect to Vercel
3. Add environment variable: `NEXT_PUBLIC_API_URL`
4. Deploy automatically

### Backend (Railway/Render)
1. Push code to GitHub
2. Connect to Railway/Render
3. Select `backend` directory
4. Deploy with Python buildpack

## ğŸ“„ License

MIT License - Feel free to use for your projects!

## ğŸ™ Acknowledgments

- PyTorch for deep learning framework
- Next.js for the amazing React framework
- FastAPI for the modern Python web framework
- RAVDESS, CREMA-D, TESS, SAVEE datasets

---

**Built with â¤ï¸ using PyTorch, FastAPI, and Next.js**
